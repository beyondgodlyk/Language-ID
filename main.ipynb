{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "I am using the pre-trained XLM-RoBERTa model and tokenizer and a classifier on top, which is used to identify the language of the query. I am using the pooled output, mean and max of hidden states as input to the classifier. Although using the mean and max of hidden states can be toggled using the flags of IdentificationModel class. \n",
    "\n",
    "I am using the [Language Identification dataset](https://huggingface.co/datasets/papluca/language-identification) which contains datasplit for train, validation and test sets. The training process is rather quick and the best model is found within 5 epochs. I am using the validation set for early stopping.\n",
    "\n",
    "Finally this model achieves an accuracy of around 99.6 % (highest 99.62 %) which is same as the [available pre-trained model](https://huggingface.co/papluca/xlm-roberta-base-language-detection) on huggingface.com.\n",
    "\n",
    "As the task mentioned, you can put your own input sentence in the last cell and use the model for identifying the language. Or if you want to execute using command line, the converted python script can be found on this [link](https://github.com/beyondgodlyk/Language-ID) in my github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, XLMRobertaModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Pretrained model of XLM-Roberta-Base\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n",
    "model = XLMRobertaModel.from_pretrained(\"FacebookAI/xlm-roberta-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Loading available dataset \n",
    "dataset = load_dataset(\"papluca/language-identification\")\n",
    "assert sorted(dataset[\"train\"].unique(\"labels\")) == sorted(dataset[\"validation\"].unique(\"labels\")) == sorted(dataset[\"test\"].unique(\"labels\"))\n",
    "\n",
    "languages = sorted(dataset[\"train\"].unique(\"labels\"))\n",
    "lang2id = {lang: i for i, lang in enumerate(languages)}\n",
    "id2lang = {i: lang for lang, i in lang2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentificationModel(nn.Module):\n",
    "    '''\n",
    "    The main model for Language Identification\n",
    "    Has a identifier which takes input based on conditions and outputs a language.\n",
    "    '''\n",
    "    def __init__(self, model, languages, use_mean_pooling, use_max_pooling):\n",
    "        super(IdentificationModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.total_num_pools = 1 + use_mean_pooling + use_max_pooling\n",
    "        self.use_mean_pooling = use_mean_pooling\n",
    "        self.use_max_pooling = use_max_pooling\n",
    "        self.hidden_size = model.config.hidden_size\n",
    "        self.languages = languages\n",
    "        self.identifier = nn.Linear(self.total_num_pools * self.hidden_size, len(languages))\n",
    "\n",
    "    def forward(self, src, attention_mask):\n",
    "        outputs = self.model(src, attention_mask = attention_mask)\n",
    "        identifier_input = outputs.pooler_output\n",
    "        if self.use_mean_pooling:\n",
    "            identifier_input = torch.cat([identifier_input, outputs.last_hidden_state.mean(dim=1)], dim=1)\n",
    "        if self.use_max_pooling:\n",
    "            identifier_input = torch.cat([identifier_input, outputs.last_hidden_state.max(dim=1).values], dim=1)\n",
    "        return self.identifier(identifier_input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    '''\n",
    "    Only returns a tuple of tokenized texts and labels, which are later used in collate_fn for tokenization\n",
    "    '''\n",
    "    def __init__(self, raw_dataset, lang2id):\n",
    "        self.texts = raw_dataset[\"text\"]\n",
    "        self.labels = raw_dataset[\"labels\"]\n",
    "        self.lang2id = lang2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.lang2id[self.labels[idx]]\n",
    "        return text, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    '''\n",
    "    Returns a tuple of lists for tokenized tokens, attention masks (used due to padding) and tensor labels respectively.\n",
    "    '''\n",
    "    texts = [tuple[0] for tuple in batch]\n",
    "    labels = [tuple[1] for tuple in batch]\n",
    "\n",
    "    tokenized_output = tokenizer(texts, return_tensors=\"pt\", padding=True, max_length=32, truncation=True)\n",
    "    tokenized_texts = tokenized_output[\"input_ids\"]\n",
    "    attention_masks = tokenized_output[\"attention_mask\"]\n",
    "    \n",
    "    return tokenized_texts, attention_masks, torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_dataset = TokenizedDataset(dataset[\"train\"], lang2id)\n",
    "val_dataset = TokenizedDataset(dataset[\"validation\"], lang2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(imodel, train_dataset, val_dataset, max_epochs):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(imodel.parameters(), lr=1e-5)\n",
    "\n",
    "    imodel.cuda()\n",
    "    \n",
    "    score_tracker = []\n",
    "    epoch_for_best_score = -1\n",
    "    for epoch in range(max_epochs):\n",
    "        imodel.train()\n",
    "        train_loader = DataLoader(train_dataset, batch_size = 32, sampler = RandomSampler(train_dataset), collate_fn=collate_fn)\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            tokenized_texts, attention_masks, labels = [x.cuda() for x in batch]\n",
    "            output = imodel(tokenized_texts, attention_masks)\n",
    "            loss_train = loss(output, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            # print(f\"Loss for epoch {epoch} is {loss_train.item()}.\")\n",
    "\n",
    "        print(f\"Training done for epoch {epoch}. Now checking performance on validation set.\")\n",
    "        # Check and save performance for validation set\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, sampler = SequentialSampler(val_dataset), collate_fn = collate_fn)\n",
    "        imodel.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch in val_loader:\n",
    "                tokenized_texts, attention_masks, labels = [x.cuda() for x in batch]\n",
    "                output = imodel(tokenized_texts, attention_masks)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            accuracy = correct / total\n",
    "            if epoch_for_best_score == -1 or accuracy > max(score_tracker):\n",
    "                epoch_for_best_score = epoch\n",
    "                torch.save(imodel.state_dict(), \"best_model.pt\")\n",
    "                print(f\"Best model saved for epoch {epoch}.\")\n",
    "            score_tracker.append(accuracy)\n",
    "            if epoch - epoch_for_best_score > 5:\n",
    "                break\n",
    "        torch.save(imodel.state_dict(), f\"model_{epoch}.pt\")\n",
    "        print(f\"Accuracy for epoch {epoch} is {accuracy}.\")\n",
    "    return score_tracker\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = IdentificationModel(model, languages, use_mean_pooling=True, use_max_pooling=True)\n",
    "\n",
    "score_tracker = train(im, train_dataset, val_dataset, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best model\n",
    "print(\"Loading model.\")\n",
    "best_model = IdentificationModel(model, languages, use_mean_pooling=True, use_max_pooling=True)\n",
    "best_model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "best_model.cuda()\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TokenizedDataset(dataset[\"test\"], lang2id)\n",
    "\n",
    "correct = 0\n",
    "total = test_dataset.__len__()\n",
    "\n",
    "print(\"Starting to check accuracy on test set.\")\n",
    "for i, test_sample in enumerate(test_dataset):\n",
    "    tokenized_output = tokenizer(test_sample[0], return_tensors=\"pt\")\n",
    "    tokenized_text = tokenized_output[\"input_ids\"]\n",
    "    attention_mask = tokenized_output[\"attention_mask\"]\n",
    "    label = torch.tensor(test_sample[1], dtype=torch.long)\n",
    "\n",
    "    tokenized_text = tokenized_text.cuda()\n",
    "    attention_mask = attention_mask.cuda()\n",
    "    label = label.cuda()\n",
    "\n",
    "    output = best_model(tokenized_text, attention_mask)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if predicted == label:\n",
    "        correct += 1\n",
    "    if i % 100 == 0:\n",
    "        print(f\"{i} samples done with accuracy {correct/(i+1)}.\")\n",
    "    # print(f\"Predicted: {id2lang[predicted.item()]}, Actual: {id2lang[label.item()]}\")\n",
    "print(f\"Accuracy on test set is {correct/total}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a sentence\n",
    "inputs = tokenizer(\"What's happening\", return_tensors=\"pt\")\n",
    "outputs = best_model(inputs[\"input_ids\"].cuda(), inputs[\"attention_mask\"].cuda())\n",
    "print(id2lang[torch.argmax(outputs).item()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
